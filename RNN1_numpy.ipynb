{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RNN1_numpy.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNpyjXkRV6fgGs1NjK6O9cI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mukeshnarendran7/Fastai2020/blob/main/RNN1_numpy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3eX98ZsFzEUK"
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V-3obdvWzIuc",
        "outputId": "47b05067-7f39-499f-dda9-f3f6438f7308"
      },
      "source": [
        "np.random.seed(42)\r\n",
        "def generate_datasets(num_sequences):\r\n",
        "  '''\r\n",
        "  - Generating a sequence of characters\r\n",
        "  '''\r\n",
        "  sequences = []\r\n",
        "  for _ in range(num_sequences):\r\n",
        "    num_tokens = np.random.randint(1, 12)\r\n",
        "    sample = ['a']*num_tokens + ['c']*num_tokens +['EOS']\r\n",
        "    sequences.append(sample)\r\n",
        "  return sequences\r\n",
        "\r\n",
        "sequences = generate_datasets(15)\r\n",
        "print('Sequences from the dataset')\r\n",
        "print(sequences[2])"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sequences from the dataset\n",
            "['a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'c', 'c', 'c', 'c', 'c', 'c', 'c', 'c', 'c', 'c', 'c', 'EOS']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p15NIgzrzSUd",
        "outputId": "604f2ce7-addd-45b3-cfee-65574c36a134"
      },
      "source": [
        "from collections import defaultdict\r\n",
        "\r\n",
        "def sequences_to_dicts(sequences):\r\n",
        "\r\n",
        "  flatten = lambda l:[item for sublist in l for item in sublist]\r\n",
        "  all_words = flatten(sequences)\r\n",
        "\r\n",
        "  word_count = defaultdict(int)\r\n",
        "  for word in flatten(sequences):\r\n",
        "    word_count[word] +=1\r\n",
        "\r\n",
        "  word_count = sorted(list(word_count.items()), key = lambda l:-l[1])\r\n",
        "  unique_words = [item[0] for item in word_count]\r\n",
        "  unique_words.append('UNK')\r\n",
        "\r\n",
        "  num_sentences, vocab_size = len(sequences), len(unique_words)\r\n",
        "  # Create dictionaries so that we can go from word to index and back\r\n",
        "  # If a word is not in our vocabulary, we assign it to coken 'UNK'\r\n",
        "  word_to_idx = defaultdict(lambda: vocab_size-1)\r\n",
        "  idx_to_word = defaultdict(lambda: 'UNK')\r\n",
        "\r\n",
        "  for idx, word in enumerate(unique_words):\r\n",
        "    word_to_idx[word] = idx \r\n",
        "    idx_to_word[idx] = word\r\n",
        "  \r\n",
        "  return word_to_idx, idx_to_word, num_sentences, vocab_size\r\n",
        "\r\n",
        "word_to_idx, idx_to_word, num_sequences, vocab_size = sequences_to_dicts(sequences)\r\n",
        "\r\n",
        "print(f'We have {num_sequences} sentences and {len(word_to_idx)} unique tokens in our dataset (including UNK).\\n')\r\n",
        "print('The index of \\'c\\' is', word_to_idx['c'])\r\n",
        "print(f'The word corresponding to index 1 is \\'{idx_to_word[1]}\\'')\r\n",
        "\r\n",
        "assert idx_to_word[word_to_idx['c']] == 'c', \\\r\n",
        "    'Consistency error: something went wrong in the conversion.'\r\n"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "We have 15 sentences and 4 unique tokens in our dataset (including UNK).\n",
            "\n",
            "The index of 'c' is 1\n",
            "The word corresponding to index 1 is 'c'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s18cU-3-5ydR",
        "outputId": "9e8ff769-4542-4059-84c2-8cd06fd64b21"
      },
      "source": [
        " from torch.utils import data\r\n",
        "\r\n",
        " class Dataset(data.Dataset):\r\n",
        "   def __init__(self, inputs, targets):\r\n",
        "    self.inputs, self.targets = inputs, targets\r\n",
        " \r\n",
        "   def __len__(self):\r\n",
        "      return len(self.targets)\r\n",
        "\r\n",
        "   def __getitem__(self, index):\r\n",
        "     X = self.inputs[index]\r\n",
        "     y = self.targtes[index]\r\n",
        "\r\n",
        "     return X, y\r\n",
        "\r\n",
        "def create_datasets(sequences, dataset_class, p_train = 0.8, p_val = 0.1, p_test = 0.1):\r\n",
        "  num_train = int(len(sequences)*p_train)\r\n",
        "  num_val = int(len(sequences)*p_val)\r\n",
        "  num_test = int(len(sequences)*p_test)\r\n",
        "\r\n",
        "  sequences_train = sequences[:num_train]\r\n",
        "  sequences_val = sequences[num_train:num_train+num_val]\r\n",
        "  sequences_test = sequences[-num_test:]\r\n",
        "\r\n",
        "  def get_inputs_targets_from_sequences(sequences):\r\n",
        "        inputs, targets = [], []\r\n",
        "\r\n",
        "        for sequence in sequences:\r\n",
        "            inputs.append(sequence[:-1])\r\n",
        "            targets.append(sequence[1:])\r\n",
        "            \r\n",
        "        return inputs, targets\r\n",
        "\r\n",
        "  inputs_train, targets_train = get_inputs_targets_from_sequences(sequences_train)\r\n",
        "  inputs_val, targets_val = get_inputs_targets_from_sequences(sequences_val)\r\n",
        "  inputs_test, targets_test = get_inputs_targets_from_sequences(sequences_test)\r\n",
        "  \r\n",
        "  training_set = dataset_class(inputs_train, targets_train)\r\n",
        "  validation_set = dataset_class(inputs_val, targets_val)\r\n",
        "  test_set = dataset_class(inputs_test, targets_test)\r\n",
        "\r\n",
        "  return training_set, validation_set, test_set\r\n",
        "\r\n",
        "training_set, validation_set, test_set = create_datasets(sequences, Dataset)\r\n",
        "\r\n",
        "print(f'We have {len(training_set)} samples in the training set.')\r\n",
        "print(f'We have {len(validation_set)} samples in the validation set.')\r\n",
        "print(f'We have {len(test_set)} samples in the test set.')\r\n"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "We have 12 samples in the training set.\n",
            "We have 1 samples in the validation set.\n",
            "We have 1 samples in the test set.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "emwAtJTunLR9"
      },
      "source": [
        "***One Hot encoding***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c0pXuEdL8eyu"
      },
      "source": [
        ""
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1-kwveTPlYMp",
        "outputId": "40667bee-bcfe-4039-ae15-33d0bb76e5ef"
      },
      "source": [
        "sequences"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['a', 'a', 'a', 'a', 'a', 'a', 'a', 'c', 'c', 'c', 'c', 'c', 'c', 'c', 'EOS'],\n",
              " ['a', 'a', 'a', 'a', 'c', 'c', 'c', 'c', 'EOS'],\n",
              " ['a',\n",
              "  'a',\n",
              "  'a',\n",
              "  'a',\n",
              "  'a',\n",
              "  'a',\n",
              "  'a',\n",
              "  'a',\n",
              "  'a',\n",
              "  'a',\n",
              "  'a',\n",
              "  'c',\n",
              "  'c',\n",
              "  'c',\n",
              "  'c',\n",
              "  'c',\n",
              "  'c',\n",
              "  'c',\n",
              "  'c',\n",
              "  'c',\n",
              "  'c',\n",
              "  'c',\n",
              "  'EOS'],\n",
              " ['a',\n",
              "  'a',\n",
              "  'a',\n",
              "  'a',\n",
              "  'a',\n",
              "  'a',\n",
              "  'a',\n",
              "  'a',\n",
              "  'c',\n",
              "  'c',\n",
              "  'c',\n",
              "  'c',\n",
              "  'c',\n",
              "  'c',\n",
              "  'c',\n",
              "  'c',\n",
              "  'EOS'],\n",
              " ['a', 'a', 'a', 'a', 'a', 'c', 'c', 'c', 'c', 'c', 'EOS'],\n",
              " ['a', 'a', 'a', 'a', 'a', 'a', 'a', 'c', 'c', 'c', 'c', 'c', 'c', 'c', 'EOS'],\n",
              " ['a',\n",
              "  'a',\n",
              "  'a',\n",
              "  'a',\n",
              "  'a',\n",
              "  'a',\n",
              "  'a',\n",
              "  'a',\n",
              "  'a',\n",
              "  'a',\n",
              "  'c',\n",
              "  'c',\n",
              "  'c',\n",
              "  'c',\n",
              "  'c',\n",
              "  'c',\n",
              "  'c',\n",
              "  'c',\n",
              "  'c',\n",
              "  'c',\n",
              "  'EOS'],\n",
              " ['a', 'a', 'a', 'c', 'c', 'c', 'EOS'],\n",
              " ['a', 'a', 'a', 'a', 'a', 'a', 'a', 'c', 'c', 'c', 'c', 'c', 'c', 'c', 'EOS'],\n",
              " ['a',\n",
              "  'a',\n",
              "  'a',\n",
              "  'a',\n",
              "  'a',\n",
              "  'a',\n",
              "  'a',\n",
              "  'a',\n",
              "  'a',\n",
              "  'a',\n",
              "  'a',\n",
              "  'c',\n",
              "  'c',\n",
              "  'c',\n",
              "  'c',\n",
              "  'c',\n",
              "  'c',\n",
              "  'c',\n",
              "  'c',\n",
              "  'c',\n",
              "  'c',\n",
              "  'c',\n",
              "  'EOS'],\n",
              " ['a',\n",
              "  'a',\n",
              "  'a',\n",
              "  'a',\n",
              "  'a',\n",
              "  'a',\n",
              "  'a',\n",
              "  'a',\n",
              "  'a',\n",
              "  'a',\n",
              "  'a',\n",
              "  'c',\n",
              "  'c',\n",
              "  'c',\n",
              "  'c',\n",
              "  'c',\n",
              "  'c',\n",
              "  'c',\n",
              "  'c',\n",
              "  'c',\n",
              "  'c',\n",
              "  'c',\n",
              "  'EOS'],\n",
              " ['a',\n",
              "  'a',\n",
              "  'a',\n",
              "  'a',\n",
              "  'a',\n",
              "  'a',\n",
              "  'a',\n",
              "  'a',\n",
              "  'c',\n",
              "  'c',\n",
              "  'c',\n",
              "  'c',\n",
              "  'c',\n",
              "  'c',\n",
              "  'c',\n",
              "  'c',\n",
              "  'EOS'],\n",
              " ['a', 'a', 'a', 'a', 'a', 'c', 'c', 'c', 'c', 'c', 'EOS'],\n",
              " ['a', 'a', 'a', 'a', 'c', 'c', 'c', 'c', 'EOS'],\n",
              " ['a',\n",
              "  'a',\n",
              "  'a',\n",
              "  'a',\n",
              "  'a',\n",
              "  'a',\n",
              "  'a',\n",
              "  'a',\n",
              "  'c',\n",
              "  'c',\n",
              "  'c',\n",
              "  'c',\n",
              "  'c',\n",
              "  'c',\n",
              "  'c',\n",
              "  'c',\n",
              "  'EOS']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gMoAZkpillsu"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}